{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"assets/ufscar.png\" alt=\"Logo UFScar\" width=\"200\" align=\"left\"/><p><center>Universidade Federal de São Carlos (UFSCar)</center><br/><font size=\"4\"><center> Departamento de Computação, campus Sorocaba </center> </font>\n",
    "\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<font size = \"4\"><center><b> Grupo 5: Análise de sentimento de reviews na Amazon </b></center></font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário possui 1509 palavras!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_processing as pp\n",
    "import analysis as anl\n",
    "import pca\n",
    "\n",
    "# Categoria da base de dados a ser lida (do disco) e processada\n",
    "# [books, kitchen_&_housewares, electronics, dvd, all]\n",
    "category = 'test'\n",
    "\n",
    "# Se positivo, adiciona bigramas para reviews negativas\n",
    "# ex: ('not', 'good') equivale a uma única feature\n",
    "hNeg = True\n",
    "\n",
    "# Se positivo, adiciona substantivos\n",
    "noun = False\n",
    "\n",
    "# Guarda as features ja processadas em X, a classe da amostra em Y e o vocabulario em vocabulary\n",
    "# hNeg e noun sao opcionais, por padrao hNeg=True, noun=False\n",
    "X, Y, vocabulary = pp.bow(category, hNeg, noun)\n",
    "\n",
    "print(\"Vocabulário possui \" + str(len(vocabulary)) + \" palavras!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separa os dados em treinamento e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X2, Y2 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# Porcentagem de amostras destinadas a base de treino\n",
    "pTrain = 0.8\n",
    "\n",
    "# Executa o holdout e retorna os indices de treino e teste, mantendo a proporcao original entre as classes\n",
    "train_index, test_index = anl.stratified_holdOut(Y, pTrain)\n",
    "\n",
    "# Guarda as amostras de treino e teste\n",
    "Xtrain, Xval = X2[train_index, :], X2[test_index, :]\n",
    "Ytrain, Yval = Y2[train_index], Y2[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleciona features com chi-quadrado (a partir dos dados de treinamento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seta o valor de alpha para o chi-quadrado. \n",
    "# alpha e opcional, por padrão alpha = 0.05\n",
    "alpha = 0.05\n",
    "\n",
    "# Chama a funcao para executar o chi-quadrado e retorna a nova base de dados reduzida\n",
    "# o novo vocabulario e os indices das features mantidas\n",
    "Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary, alpha)\n",
    "\n",
    "# Seleciona apenas as features do indice retornado pelo chi-quadrado para a base de teste\n",
    "Xval = Xval[:, index]\n",
    "\n",
    "# Converte as bases de matriz esparsa para array\n",
    "Xtrain = Xtrain.toarray()\n",
    "Xval = Xval.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features antes do chi-quadrado: 1509\n",
      "----------------------------------------\n",
      "Número de features após chi-quadrado: 26\n",
      "['written', 'love', 'heal', 'mean', 'arab', 'said', 'bad', 'true', 'die', 'well', 'paleolith', 'tri', 'wast', 'horribl', 'legal', 'wild', 'explain', 'wish', 'not', 'entir', 'good', 'whole', 'eat', 'hormon', 'pain', 'less']\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de features antes do chi-quadrado: \" + str(len(vocabulary)))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Número de features após chi-quadrado: \" + str(len(new_vocabulary)))\n",
    "print(new_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função auxiliar para calcular a Função Sigmóide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula a funcao sigmoidal  \n",
    "    \"\"\"\n",
    "    # Verifica se z e inteiro\n",
    "    if isinstance(z, int):\n",
    "        g = 0\n",
    "    \n",
    "    # se z não é um inteiro, significa que é um array e inicia com a dimensão do array\n",
    "    else:\n",
    "        g = np.zeros( z.shape );\n",
    "\n",
    "    # Calculo vetorial da funcao sigmoidal\n",
    "    g = 1/(1 + np.exp(-z))\n",
    "  \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função auxiliar para calcular a Função Custo:\n",
    "\n",
    "Calcula a função de custo, dado um vetor de thetas (theta) e um fator de regularização (lambda_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcaoCustoReg(theta, X, Y, lambda_reg):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula o custo da regressao logística\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializa o vetor de gradientes\n",
    "    grad = np.zeros( len(theta) )\n",
    "    \n",
    "    # Guarda a quantidade de amostras e features\n",
    "    m, n = X.shape\n",
    "    \n",
    "    hipotese = 0\n",
    "    reg = 0\n",
    "    \n",
    "    # Constante para evitar erro de precisao numerica\n",
    "    eps = 1e-15\n",
    "    \n",
    "    # Calcula a hipotese para cada amostra\n",
    "    hipotese = sigmoid(np.dot(X, theta))\n",
    "    \n",
    "    # Calcula o custo para cada amostra\n",
    "    cost = (-Y * np.log(hipotese + eps)) - ((1 - Y) * np.log(1 - hipotese + eps))\n",
    "    \n",
    "    # Calcula a regularizacao\n",
    "    reg = (lambda_reg/(2*m) * np.sum(theta[1:] ** 2))\n",
    "    \n",
    "    # Calcula o custo total\n",
    "    J = (1/m * np.sum(cost)) + reg\n",
    "    \n",
    "    # Não aplica a regularização para theta[0]\n",
    "    grad[0] = (np.dot(X.T, hipotese - Y)[0])/m\n",
    "    \n",
    "    # Guarda os thetas da regressao\n",
    "    grad[1:] = (np.dot(X.T, hipotese - Y)[1:])/m + (lambda_reg/m)*theta[1:]\n",
    "                      \n",
    "    return J, grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch: \n",
    "Itera sobre uma lista de possíveis valores para lambda_reg e retorna o melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y ,Xval, Yval, iteracoes):\n",
    "    \n",
    "    # Possiveis valores para lambda_reg\n",
    "    lambda_reg = [0.01, 0.05, 0.1, 0.5, 10, 50, 100, 500]\n",
    "\n",
    "    # Inicializa a variavel de retorno\n",
    "    bestLambda = lambda_reg[0]\n",
    "    \n",
    "    # Inicializa a varivel que guardara a melhor acuracia\n",
    "    bestAcc = 0\n",
    "\n",
    "    # Itera sobre os valores de lambda_reg\n",
    "    for l in lambda_reg :\n",
    "        # Executa a regressao linear e guarda os thetas\n",
    "        theta = treinamento(X,Y, l, iteracoes)\n",
    "        \n",
    "        # Faz a predicao e guarda as classes preditas e a acuracia\n",
    "        Ypred, acuracia = predicao(Xval, theta, Yval)\n",
    "        \n",
    "        # Guarda o melhor lambda de acordo com a acuracia\n",
    "        if bestAcc < acuracia :\n",
    "            bestLambda = l\n",
    "            bestAcc = acuracia\n",
    "\n",
    "\n",
    "    return bestLambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento:\n",
    "Minimiza o custo da regressão logística, retornando um vetor de thetas ótimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.optimize \n",
    "\n",
    "def treinamento(X, Y, lambda_reg, iteracoes):\n",
    "        \n",
    "    # Se for vazio, retorna None \n",
    "    if len(Y)==0:\n",
    "        return None\n",
    "    \n",
    "    # m = qtde de objetos e n = qtde de atributos por objeto    \n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Inicializa parâmetros que serao ajustados\n",
    "    theta = np.zeros(n) \n",
    "    \n",
    "    # Minimiza a funcao de custo\n",
    "    result = scipy.optimize.minimize(fun=funcaoCustoReg, x0=theta, args=(X, Y, lambda_reg),  \n",
    "                method='BFGS', jac=True, options={'maxiter': iteracoes, 'disp':False})\n",
    "\n",
    "    # Coleta os thetas retornados pela função de minimização\n",
    "    theta = result.x\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função auxiliar para predizer um conjunto de amostras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicao(X, theta, Yval):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prediz se a entrada pertence a classe 0 ou 1 usando o parametro\n",
    "    theta obtido pela regressao logistica\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    # Quantidade de amostras na base de teste\n",
    "    m = X.shape[0]   \n",
    "    \n",
    "    # Inicializa o vetor com as classes preditas\n",
    "    p = np.zeros(m, dtype=int) \n",
    "    \n",
    "    # Calcula a hipótese\n",
    "    z = np.dot(X, theta)\n",
    "    \n",
    "    # Calcula a função sigmóide\n",
    "    h_theta = sigmoid(z) \n",
    "    \n",
    "    # Para cada amostra, guarda a classe com maior probabilidade\n",
    "    for i in range(m):\n",
    "        if h_theta[i] >= 0.5:\n",
    "            p[i] = 1 \n",
    "            \n",
    "    acuracia = np.sum(p==Yval)/len(Yval)\n",
    "    \n",
    "    return p, acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predição da base de teste do Holdout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a24b8da9cdd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnumIter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlambdaReg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreinamento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdaReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mYpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macuracia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6bb04d2b0d0d>\u001b[0m in \u001b[0;36mgridSearch\u001b[0;34m(X, Y, Xval, Yval, iteracoes)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambda_reg\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Executa a regressao linear e guarda os thetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreinamento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteracoes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Faz a predicao e guarda as classes preditas e a acuracia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1b11abfbac4c>\u001b[0m in \u001b[0;36mtreinamento\u001b[0;34m(X, Y, lambda_reg, iteracoes)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Minimiza a funcao de custo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     result = scipy.optimize.minimize(fun=funcaoCustoReg, x0=theta, args=(X, Y, lambda_reg),  \n\u001b[0;32m---> 18\u001b[0;31m                 method='BFGS', jac=True, options={'maxiter': iteracoes, 'disp':False})\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Coleta os thetas retornados pela função de minimização\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m     \u001b[0mgfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-260a4e893e2b>\u001b[0m in \u001b[0;36mfuncaoCustoReg\u001b[0;34m(theta, X, Y, lambda_reg)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Não aplica a regularização para theta[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhipotese\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Guarda os thetas da regressao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad' is not defined"
     ]
    }
   ],
   "source": [
    "numIter = 50\n",
    "lambdaReg = gridSearch(Xtrain, Ytrain, Xval, Yval, numIter)\n",
    "theta = treinamento(Xtrain, Ytrain, lambdaReg, numIter)\n",
    "\n",
    "Ypred, acuracia = predicao(Xval, theta, Yval)\n",
    "print(\"Acurácia é \"+ str(acuracia))\n",
    "\n",
    "classes = np.unique(Y)\n",
    "auxResults = anl.relatorioDesempenho(Yval, Ypred, classes, imprimeRelatorio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curva_aprendizado(Xtrain, Ytrain, Xval, Yval, lambdaReg, numIter, num_iteracoes_curva = 0):\n",
    "   \n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "    \n",
    "    lambdaReg : fator de regularização da função de custo\n",
    "    \n",
    "    numIter : número de iterações da função de otimização\n",
    "    \n",
    "    num_iteracoes_curva : escalar indicando a quantidade de iterações da curva de aprendizado\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # Define a quantidade de iteracoes, por padrao, itera por cada amostra da base de treino\n",
    "    if (num_iteracoes <= 0 or num_iteracoes > len (Y)):\n",
    "        num_iteracoes = len (Y)\n",
    "    \n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    # Guarda a quantidade de classes da base\n",
    "    classes = np.unique(Y)\n",
    "    \n",
    "    # Itera e executa a Regressão Logística com i amostras da base de treino para cada iteracao\n",
    "    for i in range(10, len(Y), int (len(Y)/num_iteracoes)):\n",
    "        # Executa o treinamento e retorna os thetas\n",
    "        theta = treinamento(Xtrain[:i], Ytrain[:i], numIter, lambdaReg)\n",
    "        \n",
    "        # Realiza a predição usando a base de treino e retorna a acuracia e as classes preditas\n",
    "        Ypred, acuracia = predicao(Xtrain[:i], theta, Ytrain[:i])\n",
    "        \n",
    "        # Guarda a acuracia da iteracao usando a base de treino como teste\n",
    "        perf_train.append(acuracia)\n",
    "\n",
    "        # Realiza a predição usando a base de teste e retorna a acuracia e as classes preditas\n",
    "        Ypred, acuracia = predicao(Xval, theta, Yval)\n",
    "        \n",
    "        # Guarda a acuracia da iteracao usando a base de validacao como teste\n",
    "        perf_val.append(acuracia)\n",
    "\n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambdaReg = fator de regularizacao da regressao logistica\n",
    "# numIter = numero máximo de iterações da funcao de otimizacao\n",
    "# num_iteracoes = numero de iteracoes da curva de aprendizado, por padrao e igual ao numero de amostras da base\n",
    "curva_aprendizado(Xtrain, Ytrain, Xval, Yval, lambdaReg, numIter, num_iteracoes_curva = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k_folds as kf\n",
    "\n",
    "#Pega todos os tipos de classes \n",
    "classes = classes = np.unique(Y)\n",
    "\n",
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X3, Y3 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# separa os dados em k folds\n",
    "nFolds = 5\n",
    "folds = kf.stratified_kfolds(Y3, nFolds, classes)\n",
    "\n",
    "# Apenas para controle das iteracoes\n",
    "k = 1\n",
    "\n",
    "# cria uma lista vazia para guardar os resultados obtidos em cada fold\n",
    "resultados=[] \n",
    "\n",
    "for train_index, test_index in folds:\n",
    "\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "       \n",
    "    # Guarda as bases de treino e teste baseado nos índices de cada fold\n",
    "    Xtrain, Xval = X3[train_index, :], X3[test_index, :];\n",
    "    Ytrain, Yval= Y3[train_index], Y3[test_index];\n",
    "\n",
    "    # Executa o chi-quadrado na base do fold atual\n",
    "    Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "    Xval = Xval[:, index]\n",
    "    \n",
    "    #Converte matrizes esparsas para np arrays, para os cálculos da regressão logística\n",
    "    Xtrain = Xtrain.toarray()\n",
    "    Xval = Xval.toarray()\n",
    "\n",
    "    # Numero de iteracoes da funcao de otimizacao\n",
    "    numIter = 50\n",
    "    \n",
    "    # Executa o gridSearch e retorna o melhor fator de regularizacao \n",
    "    lambdaReg = gridSearch(Xtrain, Ytrain, Xval, Yval, numIter)\n",
    "    \n",
    "    print(\"Melhor lambda\")\n",
    "    print(lambdaReg)\n",
    "    \n",
    "    # Executa o treinamento e guarda os thetas\n",
    "    theta = treinamento(Xtrain, Ytrain, lambdaReg, numIter)\n",
    "    \n",
    "    # Faz a predicao\n",
    "    Ypred, acuracia = predicao(Xval, theta, Yval)\n",
    "\n",
    "    # Relatorio do fold\n",
    "    auxResults = anl.relatorioDesempenho(Yval, Ypred, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults )\n",
    "    \n",
    "    # Incremento da variavel de controle\n",
    "    k = k + 1\n",
    "    \n",
    "kf.mediaFolds( resultados, classes )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
