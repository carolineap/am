{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário possui 10768 palavras!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_processing as pp\n",
    "import analysis as anl\n",
    "import pca\n",
    "\n",
    "category = 'books'\n",
    "\n",
    "hNeg = True #if true, add negative bigrams for negative reviews\n",
    "noun = False #if true, add nouns\n",
    "\n",
    "X, Y, vocabulary = pp.bow(category, hNeg, noun)\n",
    "\n",
    "print(\"Vocabulário possui \" + str(len(vocabulary)) + \" palavras!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X2, Y2 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "pTrain = 0.8\n",
    "\n",
    "train_index, test_index = anl.stratified_holdOut(Y, pTrain)\n",
    "\n",
    "Xtrain, Xval = X2[train_index, :], X2[test_index, :];\n",
    "Ytrain, Yval = Y2[train_index], Y2[test_index];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "Xval = Xval[:, index]\n",
    "\n",
    "#Converte matrizes esparsas para np arrays, para os cálculos da regressão logística\n",
    "Xtrain = Xtrain.toarray()\n",
    "Xval = Xval.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features antes do chi-quadrado: 10768\n",
      "----------------------------------------\n",
      "Número de features após chi-quadrado: 258\n",
      "[('not', 'happen'), 'aw', ('not', 'wait'), 'gpu', ('not', 'make'), 'wast', 'kagan', 'appli', ('not', 'bad'), ('not', 'buy'), 'info', 'outstand', 'repetit', 'accid', 'repress', 'vagu', 'enjoy', ('not', 'believ'), 'unrealist', 'hiaasen', 'lie', 'eve', 'barber', ('not', 'find'), 'famou', 'secondari', 'bad', 'bare', ('not', 'alway'), ('not', 'not'), 'favorit', 'darl', ('not', 'know'), 'prospect', ('not', 'finish'), ('not', 'want'), 'tri', 'smith', 'alreadi', ('not', 'use'), 'sensit', 'formula', 'terribl', 'say', 'bias', 'weak', 'love', 'intens', 'great', ('never', 'seem'), 'never', 'becki', 'israel', 'help', 'recommend', 'trotski', 'stare', 'think', ('not', 'mention'), ('not', 'thought'), 'pathet', 'script', 'unseen', 'hardli', 'care', 'stick', ('not', 'say'), ('no', 'longer'), 'rambl', 'write', 'lack', 'endless', 'strateg', 'hate', 'wors', 'recycl', 'pay', 'illustr', ('not', 'get'), ('not', 'wast'), 'anderson', 'appreci', ('not', 'care'), 'highli', 'better', 'paid', 'vivid', 'go', 'weather', ('not', 'expect'), 'excel', 'drew', 'mislead', 'straight', 'instead', 'focu', ('not', 'see'), 'mention', 'skip', 'wonder', ('not', 'sure'), 'gotten', 'spend', 'danni', 'sad', 'insight', 'gray', 'even', 'notic', ('not', 'go'), 'believ', 'reinhart', 'horribl', 'dull', 'fantast', 'accept', ('not', 'alreadi'), 'whine', 'shaara', 'evil', ('not', 'give'), ('not', 'recommend'), 'elsewher', 'sean', 'pain', 'familiar', 'stun', 'twentieth', 'advanc', 'finish', 'name', ('not', 'much'), 'unfortun', 'awesom', 'remark', 'wrong', 'tire', ('not', 'feel'), 'also', 'no', 'shallow', ('not', 'tell'), 'poorli', ('not', 'read'), 'charli', 'quot', 'suppos', 'sorri', 'went', 'disjoint', ('not', 'take'), ('not', 'good'), 'predict', 'actual', ('not', 'best'), 'easi', 'buy', ('not', 'enough'), 'unforgett', 'beauti', 'neutral', 'amaz', 'wisdom', 'swisher', 'bake', 'fail', 'nicklebi', ('not', 'come'), ('not', 'work'), 'worst', 'ny', 'extraordinari', 'hard', 'soon', 'histor', 'decent', 'expect', ('not', 'write'), 'comprehens', 'bore', 'best', 'get', 'point', 'alex', ('not', 'interest'), ('not', 'true'), 'left', 'realli', 'depress', 'frustrat', ('not', 'worth'), 'super', 'ridicul', ('not', 'seem'), 'steve', 'dna', 'pp', 'half', ('not', 'complet'), 'inform', 'fascin', 'provid', 'badli', 'asid', 'anni', 'disappoint', 'program', 'silli', 'edit', ('not', 'help'), ('not', 'understand'), 'flat', 'illumin', 'entertain', 'challeng', 'import', 'save', 'slow', 'ok', 'bread', 'insult', 'narbi', 'much', 'justifi', 'obviou', 'rather', 'interest', 'poor', 'not', 'includ', 'hendrix', 'seem', 'sadli', 'pretti', 'stupid', 'got', ('not', 'think'), 'time', ('not', 'realli'), 'british', 'less', 'masterpiec', ('never', 'read'), 'useless', 'solid', 'master', 'europ', 'superfici', 'later', 'seriou', 'expand', 'human', 'simpl', ('not', 'bother'), ('not', 'need'), 'determin', 'certain', ('not', 'even')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de features antes do chi-quadrado: \" + str(len(vocabulary)))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Número de features após chi-quadrado: \" + str(len(new_vocabulary)))\n",
    "print(new_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula a funcao sigmoidal  \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(z, int):\n",
    "        g = 0\n",
    "    \n",
    "    # se z não é um inteiro, significa que é um array e inicia com a dimensão do array\n",
    "    else:\n",
    "        g = np.zeros( z.shape );\n",
    "\n",
    "    g = 1/(1 + np.exp(-z))\n",
    "  \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcaoCustoReg(theta, X, Y, lambda_reg):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula o custo da regressao logística\n",
    "    \"\"\"\n",
    "    \n",
    "    m = len(Y) #numero de exemplos de treinamento\n",
    "\n",
    "    J = 0\n",
    "    grad = np.zeros( len(theta) )\n",
    "    \n",
    "    # parâmetro de tolerância para a função sigmoide. 1-htheta não pode ser \n",
    "    # menor que eps para evitar erro de precisão numérica\n",
    "    eps = 1e-15\n",
    "    \n",
    "    #print(X)\n",
    "    \n",
    "    z = np.dot(X, theta) # z = (theta * X).sum(axis=1)\n",
    "    \n",
    "    h_theta = sigmoid(z) \n",
    "    cost = -Y * np.log(h_theta+eps) - (1 - Y) * np.log(1 - h_theta + eps)\n",
    "    J = 1/m * cost.sum()\n",
    "    \n",
    "    grad = 1/m *(X.T * (h_theta - Y)).sum(axis=1)\n",
    "                      \n",
    "    return J, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.optimize \n",
    "\n",
    "def treinamento(X, Y, lambda_reg, iteracoes):\n",
    "    \n",
    "    # se for vazio, retorna None \n",
    "    if len(Y)==0:\n",
    "        return None\n",
    "    \n",
    "    m, n = X.shape # m = qtde de objetos e n = qtde de atributos por objeto\n",
    "    theta = np.zeros(n) # Inicializa parâmetros que serao ajustados\n",
    "    # minimiza a funcao de custo\n",
    "    result = scipy.optimize.minimize(fun=funcaoCustoReg, x0=theta, args=(X, Y, lambda_reg),  \n",
    "                method='BFGS', jac=True, options={'maxiter': iteracoes, 'disp':False})\n",
    "\n",
    "    # coleta os thetas retornados pela função de minimização\n",
    "    theta = result.x\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicao(X, theta):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prediz se a entrada pertence a classe 0 ou 1 usando o parametro\n",
    "    theta obtido pela regressao logistica\n",
    "   \n",
    "    \"\"\"\n",
    "    m = X.shape[0]   \n",
    "#    Ypred = np.zeros(m, dtype=\"int\")\n",
    "    \n",
    "#    h = sigmoid( np.dot(X,theta) )\n",
    "    \n",
    "#    for i in range(m):\n",
    "#        if h[i] >= 0.5:\n",
    "#            Ypred[i] = 1\n",
    "#        else:\n",
    "#            Ypred[i] = 0\n",
    "            \n",
    "#    acuracia = np.sum(np.array(Ypred[0])==Yval)/len(Yval)\n",
    "        \n",
    "#    return Ypred, acuracia\n",
    "    p = np.zeros(m, dtype=int) \n",
    "    z = np.dot(X, theta)\n",
    "    h_theta = sigmoid(z) \n",
    "    \n",
    "    for i in range(m):\n",
    "        if h_theta[i] >= 0.5:\n",
    "            p[i] = 1 \n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = treinamento(Xtrain, Ytrain, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia é 92.25\n"
     ]
    }
   ],
   "source": [
    "Ypred = predicao(Xval, theta)\n",
    "acuracia = (np.sum(Ypred==Yval)/len(Yval)) * 100\n",
    "print(\"Acurácia é \"+ str(acuracia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.912       0.935      0.923      0\n",
      "\t0.933       0.910      0.922      1\n",
      "\t------------------------------------------------\n",
      "\t0.923       0.923      0.923      Média macro\n",
      "\t0.922       0.922      0.922      Média micro\n",
      "\n",
      "\tAcuracia: 0.922\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y)\n",
    "auxResults = anl.relatorioDesempenho(Yval, Ypred, classes, imprimeRelatorio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curva_aprendizado(Xtrain, Ytrain, Xval, Yval):\n",
    "   \n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    \n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    classes = np.unique(Y)\n",
    "    \n",
    "    for i in range(10, len(Y)):\n",
    "        \n",
    "        theta = treinamento(Xtrain[:i], Ytrain[:i], 25, 50)\n",
    "        \n",
    "        Ypred, acuracia = predicao(Xtrain[:i], theta, Ytrain[:i])\n",
    "        perf_train.append(acuracia)\n",
    "\n",
    "        Ypred, acuracia = predicao(Xval, theta, Yval)\n",
    "        perf_val.append(acuracia)\n",
    "\n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curva_aprendizado(Xtrain, Ytrain, Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y ,Xval, Yval, lambda_reg, iteracoes) :\n",
    "    bestLambda = lambda_reg[0]\n",
    "    bestAcc = 0\n",
    "    for l in lambda_reg :\n",
    "        theta = treinamento(X,Y, l, iteracoes)\n",
    "        Ypred = predicao(Xval, theta)\n",
    "        acuracia = (np.sum(Ypred==Yval)/len(Yval)) * 100\n",
    "        print(\"Acurácia é \"+ str(acuracia))\n",
    "        if bestAcc < acuracia :\n",
    "            bestLambda = l\n",
    "            bestAcc = acuracia\n",
    "        \n",
    "    print(\"Best Lambda = \", bestLambda)\n",
    "    print(\"Acc = \", bestAcc)\n",
    "    return bestLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Acurácia é 92.0\n",
      "Best Lambda =  0.001\n",
      "Acc =  92.0\n"
     ]
    }
   ],
   "source": [
    "lambda_reg = [0.001, 0.01, 0.1, 1, 0.05, 0.5, 5, 10, 50, 100, 500]\n",
    "l = gridSearch(Xtrain, Ytrain, Xval, Yval, lambda_reg, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "1-fold: \n",
      "-----------\n",
      "\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Acurácia é 91.25\n",
      "Best Lambda =  0.001\n",
      "Acc =  91.25\n",
      "\n",
      "\n",
      "\n",
      "\t==================================================\n",
      "\tMelhor parametro de regularizacao: 0.001000\n",
      "\n",
      "\tResultado no fold atual usando o melhor parametro encontrado:\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.865       0.856      0.861      0\n",
      "\t0.855       0.864      0.859      1\n",
      "\t------------------------------------------------\n",
      "\t0.860       0.860      0.860      Média macro\n",
      "\t0.860       0.860      0.860      Média micro\n",
      "\n",
      "\tAcuracia: 0.860\n",
      "\n",
      "-----------\n",
      "2-fold: \n",
      "-----------\n",
      "\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Acurácia é 90.9375\n",
      "Best Lambda =  0.001\n",
      "Acc =  90.9375\n",
      "\n",
      "\n",
      "\n",
      "\t==================================================\n",
      "\tMelhor parametro de regularizacao: 0.001000\n",
      "\n",
      "\tResultado no fold atual usando o melhor parametro encontrado:\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.875       0.871      0.873      0\n",
      "\t0.870       0.874      0.872      1\n",
      "\t------------------------------------------------\n",
      "\t0.873       0.873      0.873      Média macro\n",
      "\t0.873       0.873      0.873      Média micro\n",
      "\n",
      "\tAcuracia: 0.873\n",
      "\n",
      "-----------\n",
      "3-fold: \n",
      "-----------\n",
      "\n",
      "Acurácia é 91.5625\n",
      "Acurácia é 91.5625\n",
      "Acurácia é 91.5625\n"
     ]
    }
   ],
   "source": [
    "#K-folds\n",
    "\n",
    "import k_folds as kf\n",
    "\n",
    "# separa os dados em k folds\n",
    "nFolds = 5\n",
    "folds = kf.stratified_kfolds(Y2, nFolds, classes)\n",
    "\n",
    "k = 1\n",
    "resultados=[] # cria uma lista vazia para guardar os resultados obtidos em cada fold\n",
    "for train_index, test_index in folds:\n",
    "\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "    \n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "    \n",
    "    X_train, X_test = X2[train_index, :], X2[test_index, :];\n",
    "    Y_train, Y_test = Y2[train_index], Y2[test_index];\n",
    "    \n",
    "    X_train, new_vocabulary, index = pp.chi2(X_train, Y_train, vocabulary)\n",
    "    X_test = X_test[:,index]\n",
    "    \n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "\n",
    "    ntrain_index, ntest_index = anl.stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "    Xtrain, Xval = X_train[ntrain_index, :], X_train[ntest_index, :];\n",
    "    Ytrain, Yval = Y_train[ntrain_index], Y_train[ntest_index];\n",
    "\n",
    "        \n",
    "    #Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "    #Xval = Xval[:, index]\n",
    "\n",
    "    #Converte matrizes esparsas para np arrays, para os cálculos da regressão logística\n",
    "    Xtrain = Xtrain.toarray()\n",
    "    Xval = Xval.toarray()\n",
    "    \n",
    "    # chama a função que faz a busca em grade\n",
    "    lambda_reg = [0.001, 0.01, 0.1, 1, 0.05, 0.5, 5, 10, 50, 100, 500]\n",
    "    bestRegularization = gridSearch(Xtrain, Ytrain, Xval, Yval,lambda_reg,50)\n",
    "\n",
    "    # executa o treinamento com o melhor parâmetro de regularização encontrado\n",
    "    theta = treinamento(Xtrain, Ytrain, bestRegularization, 50)\n",
    "\n",
    "    X_test = X_test.toarray()\n",
    "    # classifica os dados de teste\n",
    "    Y_pred = predicao(X_test, theta)\n",
    "\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = anl.relatorioDesempenho(Y_test, Y_pred,classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "        \n",
    "    k+=1\n",
    "    \n",
    "print('\\n-----------\\n media-fold: \\n-----------\\n')\n",
    "kf.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
