{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário possui 10766 palavras!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_processing as pp\n",
    "import analysis as anl\n",
    "import pca\n",
    "\n",
    "category = 'books'\n",
    "\n",
    "hNeg = True #if true, add negative bigrams for negative reviews\n",
    "noun = False #if true, add nouns\n",
    "\n",
    "X, Y, vocabulary = pp.bow(category, hNeg, noun)\n",
    "\n",
    "print(\"Vocabulário possui \" + str(len(vocabulary)) + \" palavras!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X2, Y2 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "pTrain = 0.8\n",
    "\n",
    "train_index, test_index = anl.stratified_holdOut(Y, pTrain)\n",
    "\n",
    "Xtrain, Xval = X2[train_index, :], X2[test_index, :];\n",
    "Ytrain, Yval = Y2[train_index], Y2[test_index];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "Xval = Xval[:, index]\n",
    "\n",
    "#Converte matrizes esparsas para np arrays, para os cálculos da rede neural\n",
    "Xtrain = Xtrain.toarray()\n",
    "Xval = Xval.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features antes do chi-quadrado: 10766\n",
      "----------------------------------------\n",
      "Número de features após chi-quadrado: 722\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de features antes do chi-quadrado: \" + str(len(vocabulary)))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Número de features após chi-quadrado: \" + str(len(new_vocabulary)))\n",
    "#print(new_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    z = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "    g = sigmoid(z)*(1 - sigmoid(z))    \n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "def funcaoCusto_backp(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, flagreg = False,lambda_reg = 1):\n",
    "    \n",
    "    # Extrai os parametros de nn_params e alimenta as variaveis Theta1 e Theta2.\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # Qtde de amostras\n",
    "    m = X.shape[0]\n",
    "         \n",
    "    #Custo\n",
    "    J = 0\n",
    "    \n",
    "    #Theta das redes neurais\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "    eps = 1e-15\n",
    "\n",
    "    \n",
    "    rotulos = np.zeros((len(y), num_labels), dtype=int) \n",
    "    for i in range(len(rotulos)):\n",
    "        rotulos[i][y[i]] = 1\n",
    "\n",
    "    a1 = np.insert(X, 0, np.ones(m, dtype=int), axis=1)\n",
    "    z2 = np.dot(a1, Theta1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.insert(a2, 0, np.ones(a2.shape[0], dtype=int), axis=1)\n",
    "    z3 = np.dot(a2, Theta2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    \n",
    "    delta3 = a3 - rotulos\n",
    "    delta2 = np.dot(delta3, Theta2[:, 1:]) * sigmoidGradient(z2)\n",
    "\n",
    "    if flagreg == True :\n",
    "        reg = (lambda_reg/(2*m))*(np.sum(Theta1[:, 1:] ** 2) + np.sum(Theta2[:, 1:] ** 2)) \n",
    "\n",
    "        J += reg\n",
    "    \n",
    "        delta3 = a3 - rotulos\n",
    "        delta2 = np.dot(delta3, Theta2[:, 1:]) * sigmoidGradient(z2)\n",
    "\n",
    "        Theta1_grad[:, 0] = (np.dot(delta2.T, a1)[:, 0]/m) \n",
    "        Theta1_grad[:, 1:] = (np.dot(delta2.T, a1)[:, 1:]/m) + (lambda_reg/m)*Theta1[:, 1:]\n",
    "\n",
    "        Theta2_grad[:, 0] = (np.dot(delta3.T, a2)[:, 0]/m) \n",
    "        Theta2_grad[:, 1:] = (np.dot(delta3.T, a2)[:, 1:]/m) + (lambda_reg/m)*Theta2[:, 1:]\n",
    "    \n",
    "    else:    \n",
    "        Theta1_grad = np.dot(delta2.T, a1)/m\n",
    "        Theta2_grad = np.dot(delta3.T, a2)/m\n",
    "     \n",
    "    J = np.sum(-rotulos*np.log(a3+eps) - (1 - rotulos)*np.log(1 - a3+eps))/m\n",
    "\n",
    "    grad = np.concatenate([np.ravel(Theta1_grad), np.ravel(Theta2_grad)])\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicao(Theta1, Theta2, Xval, Yval):\n",
    "\n",
    "    m = Xval.shape[0] # número de amostras\n",
    "    num_labels = Theta2.shape[0]\n",
    "    \n",
    "    p = np.zeros(m)\n",
    "\n",
    "    a1 = np.hstack( [np.ones([m,1]), Xval] )\n",
    "    h1 = sigmoid( np.dot(a1, Theta1.T) )\n",
    "\n",
    "    a2 = np.hstack( [np.ones([m,1]), h1] ) \n",
    "    h2 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "    \n",
    "    Ypred = np.argmax(h2,axis=1)\n",
    "    \n",
    "    acuracia = np.sum(Ypred==Yval)/len(Yval)   \n",
    "        \n",
    "    return Ypred, acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y ,Xval, Yval):\n",
    "    \n",
    "    lambda_rnn = [0.01, 0.1, 10, 100]\n",
    "    \n",
    "    bestLambda = lambda_rnn[0]\n",
    "    bestAcc = 0\n",
    "    \n",
    "    for l in lambda_rnn:\n",
    "        Theta1, Theta2 = redes_neurais(Xtrain, Ytrain, l)\n",
    "        Ypred, acuracia = predicao(Theta1, Theta2, Xval, Yval)\n",
    "        if bestAcc < acuracia :\n",
    "            bestLambda = l\n",
    "            bestAcc = acuracia\n",
    "        \n",
    "    return bestLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redes_neurais (Xtrain, Ytrain, lambda_rnn):\n",
    "\n",
    "    input_layer_size  = Xtrain.shape[1]  # 20x20 dimensao das imagens de entrada\n",
    "    hidden_layer_size = int((input_layer_size + 2)*2/3)   \n",
    "    num_labels = 2          # 10 rotulos, de 1 a 10  \n",
    "                         #  (observe que a classe \"0\" recebe o rotulo 10)\n",
    "    epsilon_init = 0.12\n",
    "    \n",
    "    # carregando os pesos da camada 1\n",
    "    Theta1 =  np.random.RandomState(10).rand(hidden_layer_size, 1 + input_layer_size) * 2 * epsilon_init - epsilon_init\n",
    "    \n",
    "    # carregando os pesos da camada 2\n",
    "    Theta2 = np.random.RandomState(10).rand(num_labels, 1 + hidden_layer_size) * 2 * epsilon_init - epsilon_init\n",
    "    \n",
    "    # concatena os pesos em um único vetor\n",
    "    initial_rna_params = np.concatenate([np.ravel(Theta1), np.ravel(Theta2)])\n",
    "    \n",
    "    MaxIter = 5000\n",
    "    \n",
    "    #lamba_reg = 1\n",
    "    \n",
    "    # Minimiza a funcao de custo\n",
    "    result = scipy.optimize.minimize(fun=funcaoCusto_backp, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, Xtrain, Ytrain,True,lambda_rnn),  \n",
    "                    method='TNC', jac=True, options={'maxiter': MaxIter})\n",
    "    \n",
    "    # Coleta os pesos retornados pela função de minimização\n",
    "    nn_params = result.x\n",
    "    \n",
    "    # Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "    \n",
    "    return Theta1, Theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia é 91.75\n"
     ]
    }
   ],
   "source": [
    "lambda_rnn = gridSearch(Xtrain, Ytrain, Xval, Yval)\n",
    "Theta1, Theta2 = redes_neurais(Xtrain, Ytrain, lambda_rnn)\n",
    "Ypred, acuracia = predicao(Theta1, Theta2, Xval, Yval)\n",
    "print(\"Acurácia é \"+ str(acuracia*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.946       0.898      0.922      0\n",
      "\t0.887       0.940      0.913      1\n",
      "\t------------------------------------------------\n",
      "\t0.917       0.919      0.918      Média macro\n",
      "\t0.917       0.917      0.917      Média micro\n",
      "\n",
      "\tAcuracia: 0.917\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y)\n",
    "auxResults = anl.relatorioDesempenho(Yval, Ypred, classes, imprimeRelatorio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curva_aprendizado(X, Y, Xval, Yval, lambda_rnn):\n",
    "   \n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    classes = np.unique(Y)\n",
    "    \n",
    "    for i in range(10, len(Y)):\n",
    "        \n",
    "        \n",
    "        Theta1, Theta2 = redes_neurais(X[:i], Y[:i], lambda_rnn)\n",
    "\n",
    "        Ypred, acuracia = predicao(Theta1, Theta2, X[:i], Y[:i])\n",
    "        perf_train.append(acuracia)\n",
    "\n",
    "        Ypred, acuracia = predicao(Theta1, Theta2, Xval, Yval)\n",
    "        perf_val.append(acuracia)\n",
    "\n",
    "\n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curva_aprendizado(Xtrain, Ytrain, Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "1-fold: \n",
      "-----------\n",
      "\n",
      "Melhor lambda\n",
      "10\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.910       0.839      0.873      0\n",
      "\t0.825       0.902      0.862      1\n",
      "\t------------------------------------------------\n",
      "\t0.867       0.870      0.869      Média macro\n",
      "\t0.868       0.868      0.868      Média micro\n",
      "\n",
      "\tAcuracia: 0.868\n",
      "\n",
      "-----------\n",
      "2-fold: \n",
      "-----------\n",
      "\n",
      "Melhor lambda\n",
      "10\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.880       0.846      0.863      0\n",
      "\t0.840       0.875      0.857      1\n",
      "\t------------------------------------------------\n",
      "\t0.860       0.861      0.860      Média macro\n",
      "\t0.860       0.860      0.860      Média micro\n",
      "\n",
      "\tAcuracia: 0.860\n",
      "\n",
      "-----------\n",
      "3-fold: \n",
      "-----------\n",
      "\n",
      "Melhor lambda\n",
      "10\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.935       0.940      0.937      0\n",
      "\t0.940       0.935      0.938      1\n",
      "\t------------------------------------------------\n",
      "\t0.938       0.938      0.938      Média macro\n",
      "\t0.938       0.938      0.938      Média micro\n",
      "\n",
      "\tAcuracia: 0.938\n",
      "\n",
      "-----------\n",
      "4-fold: \n",
      "-----------\n",
      "\n",
      "Melhor lambda\n",
      "10\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.895       0.891      0.893      0\n",
      "\t0.890       0.894      0.892      1\n",
      "\t------------------------------------------------\n",
      "\t0.893       0.893      0.893      Média macro\n",
      "\t0.892       0.892      0.892      Média micro\n",
      "\n",
      "\tAcuracia: 0.892\n",
      "\n",
      "-----------\n",
      "5-fold: \n",
      "-----------\n",
      "\n",
      "Melhor lambda\n",
      "10\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.950       0.884      0.916      0\n",
      "\t0.875       0.946      0.909      1\n",
      "\t------------------------------------------------\n",
      "\t0.912       0.915      0.914      Média macro\n",
      "\t0.912       0.912      0.912      Média micro\n",
      "\n",
      "\tAcuracia: 0.912\n",
      "\n",
      "-----------\n",
      "Media-fold: \n",
      "-----------\n",
      "\n",
      "\n",
      "\tRevocacao   Precisao   F-medida   Classe\n",
      "\t0.914       0.880      0.896      0\n",
      "\t0.874       0.910      0.892      1\n",
      "\t---------------------------------------------------------------------\n",
      "\t0.894       0.895      0.895      Média macro\n",
      "\t0.894       0.894      0.894      Média micro\n",
      "\n",
      "\tAcuracia: 0.894\n"
     ]
    }
   ],
   "source": [
    "import k_folds as kf\n",
    "\n",
    "#Pega todos os tipos de classes \n",
    "classes = classes = np.unique(Y)\n",
    "\n",
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X3, Y3 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# separa os dados em k folds\n",
    "nFolds = 5\n",
    "folds = kf.stratified_kfolds(Y3, nFolds, classes)\n",
    "\n",
    "k = 1\n",
    "resultados=[] # cria uma lista vazia para guardar os resultados obtidos em cada fold\n",
    "\n",
    "for train_index, test_index in folds:\n",
    "\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    Xtrain, Xval = X3[train_index, :], X3[test_index, :];\n",
    "    Ytrain, Yval= Y3[train_index], Y3[test_index];\n",
    "\n",
    "    Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "    Xval = Xval[:, index]\n",
    "    \n",
    "    #Converte matrizes esparsas para np arrays, para os cálculos da rede neural\n",
    "    Xtrain = Xtrain.toarray()\n",
    "    Xval = Xval.toarray()\n",
    "    \n",
    "    lambda_rnn = gridSearch(Xtrain, Ytrain, Xval, Yval)\n",
    "    Theta1, Theta2 = redes_neurais(Xtrain, Ytrain, lambda_rnn)\n",
    "    Ypred, acuracia = predicao(Theta1, Theta2, Xval, Yval)\n",
    "    \n",
    "    print(\"Melhor lambda\")\n",
    "    print(lambda_rnn)\n",
    "    \n",
    "    auxResults = anl.relatorioDesempenho(Yval, Ypred, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults )\n",
    "    \n",
    "    k = k + 1\n",
    "    \n",
    "kf.mediaFolds( resultados, classes )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
