{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré processamento: \n",
    "Funções do arquivo pre_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/sy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "    abl  absolut  accomplish  acquir  action  actual  acupunctur  adam  advic  \\\n",
      "0   0.0      0.0         0.0     0.0     0.0     1.0         0.0   0.0    0.0   \n",
      "1   0.0      0.0         1.0     0.0     0.0     0.0         1.0   0.0    0.0   \n",
      "2   0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "3   0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "4   0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "5   0.0      0.0         0.0     0.0     0.0     1.0         0.0   0.0    0.0   \n",
      "6   0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "7   0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "8   0.0      0.0         0.0     0.0     0.0     0.0         0.0   1.0    0.0   \n",
      "9   0.0      0.0         0.0     0.0     1.0     0.0         0.0   0.0    0.0   \n",
      "10  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "11  1.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "12  0.0      1.0         0.0     1.0     0.0     0.0         0.0   0.0    0.0   \n",
      "13  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "14  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "15  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "16  0.0      0.0         0.0     0.0     0.0     1.0         0.0   0.0    0.0   \n",
      "17  0.0      1.0         0.0     0.0     0.0     0.0         0.0   1.0    0.0   \n",
      "18  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "19  0.0      0.0         0.0     0.0     1.0     0.0         0.0   0.0    0.0   \n",
      "20  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "21  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "22  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    1.0   \n",
      "23  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "24  0.0      0.0         0.0     0.0     1.0     0.0         0.0   0.0    0.0   \n",
      "25  0.0      0.0         0.0     0.0     0.0     0.0         0.0   0.0    0.0   \n",
      "\n",
      "    advis  ...   write  writer  written  wrong  yael  year  yeor  yet  yoga  \\\n",
      "0     0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "1     0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   1.0   \n",
      "2     0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "3     0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  1.0   0.0   \n",
      "4     0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "5     0.0  ...     1.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "6     0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "7     0.0  ...     1.0     1.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "8     0.0  ...     1.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "9     0.0  ...     0.0     0.0      1.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "10    0.0  ...     0.0     0.0      0.0    0.0   0.0   1.0   0.0  0.0   0.0   \n",
      "11    0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "12    0.0  ...     0.0     1.0      1.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "13    0.0  ...     0.0     0.0      0.0    0.0   0.0   2.0   0.0  0.0   0.0   \n",
      "14    0.0  ...     0.0     0.0      1.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "15    0.0  ...     0.0     0.0      0.0    0.0   0.0   2.0   0.0  0.0   0.0   \n",
      "16    0.0  ...     2.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "17    1.0  ...     0.0     0.0      0.0    1.0   0.0   0.0   0.0  0.0   0.0   \n",
      "18    0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "19    0.0  ...     0.0     0.0      0.0    0.0   0.0   1.0   0.0  0.0   0.0   \n",
      "20    0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "21    0.0  ...     1.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "22    0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "23    0.0  ...     0.0     0.0      0.0    0.0   0.0   1.0   0.0  0.0   0.0   \n",
      "24    0.0  ...     0.0     0.0      0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
      "25    0.0  ...     0.0     0.0      0.0    0.0   1.0   0.0   1.0  2.0   0.0   \n",
      "\n",
      "    york  \n",
      "0    0.0  \n",
      "1    0.0  \n",
      "2    0.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "5    1.0  \n",
      "6    0.0  \n",
      "7    0.0  \n",
      "8    0.0  \n",
      "9    0.0  \n",
      "10   0.0  \n",
      "11   0.0  \n",
      "12   0.0  \n",
      "13   0.0  \n",
      "14   0.0  \n",
      "15   0.0  \n",
      "16   0.0  \n",
      "17   0.0  \n",
      "18   0.0  \n",
      "19   0.0  \n",
      "20   0.0  \n",
      "21   0.0  \n",
      "22   0.0  \n",
      "23   0.0  \n",
      "24   0.0  \n",
      "25   0.0  \n",
      "\n",
      "[26 rows x 1099 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pre_processing as pp\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "category = 'test'\n",
    "\n",
    "df, df_chi2, Y = pp.bow(category)\n",
    "X = df.values\n",
    "X_chi = df_chi2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout estratificado para separar dados para treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = pp.stratified_holdOut(Y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento\n",
    "Xtrain = X[train_index]\n",
    "Xtrain_chi = X_chi[train_index]\n",
    "Ytrain = Y[train_index]\n",
    "\n",
    "#Validação\n",
    "Xval =  X[test_index]\n",
    "Xval_chi = X_chi[test_index]\n",
    "Yval = Y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-vizinhos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "K = 3\n",
      "Acuracia sem chi-squared é 0.5\n",
      "Acuracia com chi-squared é 0.6666666666666666\n",
      "-------------------------------------\n",
      "K = 5\n",
      "Acuracia sem chi-squared é 0.5\n",
      "Acuracia com chi-squared é 0.6666666666666666\n",
      "-------------------------------------\n",
      "K = 7\n",
      "Acuracia sem chi-squared é 0.5\n",
      "Acuracia com chi-squared é 0.7222222222222222\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import k_neighbors as knn\n",
    "\n",
    "for j in range(3, 8, 2):\n",
    "    \n",
    "    K = j\n",
    "    \n",
    "    print(\"K = \" + str(K))\n",
    "    \n",
    "    classes = []\n",
    "\n",
    "    for i in range(Xval.shape[0]):\n",
    "        y = knn.knn(Xval[i], Xtrain, Ytrain, K)\n",
    "        classes.append(y)\n",
    "\n",
    "    acuracia = np.sum(classes==Yval)/len(Yval)\n",
    "    print(\"Acuracia sem chi-squared é \" + str(acuracia))    \n",
    "\n",
    "    classes = []\n",
    "    \n",
    "    for i in range(Xval.shape[0]):\n",
    "        y = knn.knn(Xval_chi[i], Xtrain_chi, Ytrain, K)\n",
    "        classes.append(y)\n",
    "        \n",
    "    acuracia = np.sum(classes==Yval)/len(Yval)\n",
    "    print(\"Acuracia com chi-squared é \" + str(acuracia))    \n",
    "    \n",
    "    print(\"-------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000002\n",
      "         Iterations: 19\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 20\n",
      "Acuracia sem chi-squared é 55.5555555556\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346580\n",
      "         Iterations: 17\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Acuracia com chi-squared é 66.6666666667\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import regressao_logistica as rl\n",
    "\n",
    "import scipy.optimize \n",
    "\n",
    "# Configura se a função custo utiliza a regularização\n",
    "reg = 0\n",
    "# Configura o parametro de regularizacao lambda igual a 1\n",
    "lambda_reg = 1\n",
    "# Algumas configuracoes do gradiente descente\n",
    "iteracoes = 50\n",
    "theta = np.zeros(Xval.shape[1]) # Inicializa parâmetros que serao ajustados\n",
    "\n",
    "# minimiza a funcao de custo\n",
    "result = scipy.optimize.minimize(fun=rl.funcaoCusto, x0=theta, args=(Xtrain, Ytrain,reg,lambda_reg),  \n",
    "                method='BFGS', jac=True, options={'maxiter': iteracoes, 'disp':True})\n",
    "# coleta os thetas retornados pela função de minimização\n",
    "theta = result.x\n",
    "\n",
    "# realiza a predição dos dados\n",
    "p = rl.predicao(theta, Xval)\n",
    "\n",
    "acuracia = np.mean(p == Yval) * 100\n",
    "print(\"Acuracia sem chi-squared é \" + str(acuracia)) \n",
    "\n",
    "theta = np.zeros(Xval_chi.shape[1]) # Inicializa parâmetros que serao ajustados\n",
    "\n",
    "# minimiza a funcao de custo\n",
    "result = scipy.optimize.minimize(fun=rl.funcaoCusto, x0=theta, args=(Xtrain_chi, Ytrain,reg,lambda_reg),  \n",
    "                method='BFGS', jac=True, options={'maxiter': iteracoes, 'disp':True})\n",
    "# coleta os thetas retornados pela função de minimização\n",
    "theta = result.x\n",
    "\n",
    "# realiza a predição dos dados\n",
    "p = rl.predicao(theta, Xval_chi)\n",
    "\n",
    "acuracia = np.mean(p == Yval) * 100\n",
    "print(\"Acuracia com chi-squared é \" + str(acuracia)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Acuracia sem chi-squared é 0.5\n",
      "Acuracia com chi-squared é 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import naive_bayes as nb\n",
    "\n",
    "#Sem chi\n",
    "probPos, probNeg, pPos, pNeg = nb.calcularProbabilidades(Xtrain, Ytrain)\n",
    "classes = []\n",
    "\n",
    "for i in range(Xval.shape[0]):\n",
    "    y = nb.classificacao(Xval[i], probPos, probNeg, pPos, pNeg)\n",
    "    classes.append(y)\n",
    "\n",
    "acuracia = np.sum(classes==Yval)/len(Yval)\n",
    "print(\"Acuracia sem chi-squared é \" + str(acuracia))    \n",
    "\n",
    "#Com chi\n",
    "probPos, probNeg, pPos, pNeg = nb.calcularProbabilidades(Xtrain_chi, Ytrain)\n",
    "classes = []\n",
    "for i in range(Xval.shape[0]):\n",
    "    y = nb.classificacao(Xval_chi[i], probPos, probNeg, pPos, pNeg)\n",
    "    classes.append(y)\n",
    "\n",
    "acuracia = np.sum(classes==Yval)/len(Yval)\n",
    "print(\"Acuracia com chi-squared é \" + str(acuracia))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /home/sy/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "<bound method CategorizedCorpusReader.fileids of <CategorizedPlaintextCorpusReader in '/home/sy/nltk_data/corpora/movie_reviews'>>\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "negcutoff = int(len(negfeats)*3/4)\n",
    "poscutoff = int(len(posfeats)*3/4)\n",
    "\n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "\n",
    "training_set = trainfeats\n",
    "test_set = testfeats\n",
    "\n",
    "#for i in range(len(Ytrain)) :\n",
    "#    training_set.append((Xtrain_chi[i,:].tolist(), Ytrain[i]))\n",
    "#for i in range(len(Yval)) :    \n",
    "#    test_set.append((Xval_chi[i,:].tolist(), Yval[i]))\n",
    "\n",
    "#def list_to_dict(words_list):\n",
    "#  return dict([(word, True) for word in words_list])\n",
    "\n",
    "training_set_formatted = [(list_to_dict(element[0]), element[1]) for element in training_set] \n",
    "numIterations = 100\n",
    " \n",
    "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "classifier = nltk.MaxentClassifier.train(training_set_formatted, algorithm, max_iter=numIterations)\n",
    "#classifier.show_most_informative_features(10)\n",
    "\n",
    "test_set_formatted = [(list_to_dict(element[0]), element[1]) for element in test_set] \n",
    "classes = []\n",
    "for review in test_set_formatted:\n",
    "    label = review[1]\n",
    "    text = review[0]\n",
    "    classes.append(classifier.classify(text))\n",
    "    \n",
    "acuracia = np.sum(classes==Yval)/len(Yval)\n",
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia com chi-squared é 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(Xtrain_chi, Ytrain)\n",
    "classes = clf.predict(Xval_chi)\n",
    "acuracia = np.sum(classes==Yval)/len(Yval)\n",
    "print(\"Acuracia com chi-squared é \" + str(acuracia))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INVENTAR +++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
