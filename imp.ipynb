{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré processamento: \n",
    "Funções do arquivo pre_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário possui 24637 palavras!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_processing as pp\n",
    "import analysis as anl\n",
    "import pca\n",
    "\n",
    "category = 'all'\n",
    "\n",
    "hNeg = False #if true, add negative bigrams for negative reviews\n",
    "noun = True #if true, add nouns\n",
    "\n",
    "X, Y, vocabulary = pp.bow(category, hNeg, noun)\n",
    "\n",
    "print(\"Vocabulário possui \" + str(len(vocabulary)) + \" palavras!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X2, Y2 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "#X2, Y2 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "pTrain = 0.8\n",
    "\n",
    "train_index, test_index = anl.stratified_holdOut(Y, pTrain)\n",
    "\n",
    "Xtrain, Xval = X2[train_index, :], X2[test_index, :]\n",
    "Ytrain, Yval = Y2[train_index], Y2[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "#Xval = Xval[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features antes do chi-quadrado: 24637\n",
      "----------------------------------------\n",
      "Número de features após chi-quadrado: 2916\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de features antes do chi-quadrado: \" + str(len(vocabulary)))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Número de features após chi-quadrado: \" + str(len(new_vocabulary)))\n",
    "#print(new_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Clssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "def entropy(Y) :\n",
    "    entropia = st.entropy(Y)\n",
    "    return entropia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoGain(X, Y, split_atribute) :\n",
    "    totalEntropy = entropy(Y)\n",
    "    valores, count = np.unique(X[:,split_atribute], return_counts = True)\n",
    "    entropyPond = 0\n",
    "    for i in range(len(valores)) : \n",
    "        \n",
    "        myatt = entropy(np.where(X[:,split_atribute]==valores[i])[0])\n",
    "        entropyPond += np.sum([(count[i]/np.sum(count)*myatt)])\n",
    "      \n",
    "    informationGain =  totalEntropy - entropyPond\n",
    "    \n",
    "    return informationGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(X, originalX, Y, originalY, features, parentNodeClasse = None) :\n",
    "    if (len(np.unique(Y)) <= 1) :\n",
    "        return np.unique(Y)[0]\n",
    "    if (len(X)==0) :\n",
    "        return np.unique(originalY)[np.argmax(np.unique(originalY, return_counts = True))]\n",
    "    if (len(features)==0) :\n",
    "        return parentNodeClasse\n",
    "    else :\n",
    "        parentNodeClasse = np.unique(Y)[np.argmax(np.unique(Y,return_counts = True)[1])]\n",
    "        bestGain = -330\n",
    "        for f in features :\n",
    "            gain_new = infoGain(X,Y, f)\n",
    "            if(gain_new > bestGain) : \n",
    "                bestGain = gain_new\n",
    "                bestFeature = f\n",
    "                \n",
    "        tree = {bestFeature:{}}\n",
    "        \n",
    "        #features.delete(bestFeature)\n",
    "        features = [i for i in features if i != bestFeature]\n",
    "        for value in np.unique(X[:,bestFeature]) :\n",
    "            value = value\n",
    "        \n",
    "            subX_indes = np.where(X[:,bestFeature] == value)[0]\n",
    "            subX = X[subX_indes]\n",
    "            subY = Y[np.where(X[:,bestFeature] == value)]\n",
    "            subTree = ID3(subX, X, subY, Y, features, parentNodeClasse)\n",
    "            \n",
    "            tree[bestFeature][value] = subTree\n",
    "            \n",
    "        return(tree) \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, tree,default=1) :\n",
    "    features = np.arange(Xtrain.shape[1])\n",
    "    for f in features :\n",
    "        if f in list(tree.keys()) :\n",
    "            try :\n",
    "                classe = tree[f][row[f]]\n",
    "            except:\n",
    "                return default    \n",
    "            \n",
    "            classe = tree[f][row[f]]\n",
    "            if isinstance(classe,dict):\n",
    "                return predict(row,classe)\n",
    "            else:\n",
    "                return classe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test, tree) :\n",
    "    result = []\n",
    "    for row in range(test.shape[0]) :\n",
    "        t = test[row]\n",
    "        result.append(predict(t, tree))\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2894\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape[1])\n",
    "\n",
    "from pprint import pprint\n",
    "features_index = np.arange(Xtrain.shape[1])\n",
    "#Xtrain = Xtrain.toarray()\n",
    "#tree = ID3(Xtrain, Xtrain ,Ytrain, Ytrain, features_index)\n",
    "\n",
    "#pprint(tree)\n",
    "result = test(Xval, tree)\n",
    "acuracia = np.sum(result==Yval)/len(Yval)\n",
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "1-fold: \n",
      "-----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sy/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:2508: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n"
     ]
    }
   ],
   "source": [
    "import k_folds as kf\n",
    "\n",
    "#Pega todos os tipos de classes \n",
    "classes = classes = np.unique(Y)\n",
    "\n",
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X3, Y3 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "# separa os dados em k folds\n",
    "nFolds = 5\n",
    "folds = kf.stratified_kfolds(Y3, nFolds, classes)\n",
    "\n",
    "k = 1\n",
    "resultados=[] # cria uma lista vazia para guardar os resultados obtidos em cada fold\n",
    "\n",
    "for train_index, test_index in folds:\n",
    "\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "        \n",
    "    #Xtrain, Xval = X3[train_index, :], X3[test_index, :];\n",
    "    #Ytrain, Yval= Y3[train_index], Y3[test_index];\n",
    "\n",
    "    #Xtrain, new_vocabulary, index = pp.chi2(Xtrain, Ytrain, vocabulary)\n",
    "    #Xval = Xval[:, index]\n",
    "    \n",
    "    #Converte matrizes esparsas para np arrays, para os cálculos da rede neural\n",
    "    #Xtrain = Xtrain.toarray()\n",
    "    #Xval = Xval.toarray()\n",
    "    \n",
    "    features_index = np.arange(Xtrain.shape[1])\n",
    "    Xtrain = Xtrain.toarray()\n",
    "    tree = ID3(Xtrain, Xtrain ,Ytrain, Ytrain, features_index)\n",
    "\n",
    "    #pprint(tree)\n",
    "    Ypred = test(Xval.toarray(), tree)\n",
    "    auxResults = anl.relatorioDesempenho(Yval, Ypred, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults )\n",
    "    \n",
    "    k = k + 1\n",
    "    \n",
    "kf.mediaFolds( resultados, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
